{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/matdekoning/FakeNewsClassifier/blob/master/FakeNewsClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8huogek1v8D"
   },
   "source": [
    "# **Fake news classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ofNGIHq02U3R",
    "outputId": "b6e306a0-9071-4fe5-a03b-7bfde0dcb8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct version of Tensorflow installed.\n"
     ]
    }
   ],
   "source": [
    "# First we import the required libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "# Check tensorflow version\n",
    "if float(tf.__version__[0]) < 2.0:\n",
    "  print('Updating tensorflow')\n",
    "  !pip install tensorflow==2.0\n",
    "else:\n",
    "  print('Correct version of Tensorflow installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "7YHDGDv7_VU2",
    "outputId": "94e8ecc2-88df-4681-efba-6cff72dd8374"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        20800\n",
       "title     20800\n",
       "author    20800\n",
       "text      20800\n",
       "label     20800\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the data\n",
    "\n",
    "df = pd.read_csv('../data/raw.csv')\n",
    "df = df.fillna(' ')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "qHas2w8Dj5dq",
    "outputId": "86c149a3-4565-48ec-8733-2ab2f4d50525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238934\n"
     ]
    }
   ],
   "source": [
    "# Tokenize text\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size=len(word_index)\n",
    "print(vocab_size)\n",
    "\n",
    "# Padding data\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "padded = pad_sequences(sequences, maxlen=500, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4VVJUN55b6H"
   },
   "outputs": [],
   "source": [
    "split = 0.25\n",
    "split_n = int(round(len(padded)*(1-split),0))\n",
    "\n",
    "train_data = padded[:split_n]\n",
    "train_labels = df['label'].values[:split_n]\n",
    "test_data = padded[split_n:]\n",
    "test_labels = df['label'].values[split_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "4_cKfNmzkH2v",
    "outputId": "724593b4-c735-40a2-e798-189cc840f507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Import tensor representations for words\n",
    "embeddings_index = {};\n",
    "with open('glove.6B.100d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split();\n",
    "        word = values[0];\n",
    "        coefs = np.asarray(values[1:], dtype='float32');\n",
    "        embeddings_index[word] = coefs;\n",
    "print(len(coefs))\n",
    "\n",
    "embeddings_matrix = np.zeros((vocab_size+1, 100));\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word);\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjkzdejAeSiu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 100)         23893500  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 32)          3232      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, None, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, None, 1)           33        \n",
      "=================================================================\n",
      "Total params: 23,897,821\n",
      "Trainable params: 4,321\n",
      "Non-trainable params: 23,893,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the architecture of the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size+1, 100, weights=[embeddings_matrix], trainable=False),\n",
    "    \n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_3_input:0' shape=(None, None) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "colab_type": "code",
    "id": "ozzZOuJClDPG",
    "outputId": "75dba8ae-e001-4cfa-d79a-d3b95afdc981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15600 samples, validate on 5200 samples\n",
      "Epoch 1/5\n",
      "15600/15600 [==============================] - 3s 210us/sample - loss: 0.6433 - accuracy: 0.6316 - val_loss: 0.6398 - val_accuracy: 0.6366\n",
      "Epoch 2/5\n",
      "15600/15600 [==============================] - 3s 213us/sample - loss: 0.6433 - accuracy: 0.6317 - val_loss: 0.6386 - val_accuracy: 0.6375\n",
      "Epoch 3/5\n",
      "15600/15600 [==============================] - 3s 200us/sample - loss: 0.6434 - accuracy: 0.6316 - val_loss: 0.6386 - val_accuracy: 0.6378\n",
      "Epoch 4/5\n",
      "15600/15600 [==============================] - 3s 207us/sample - loss: 0.6430 - accuracy: 0.6319 - val_loss: 0.6395 - val_accuracy: 0.6365\n",
      "Epoch 5/5\n",
      "15600/15600 [==============================] - 3s 209us/sample - loss: 0.6433 - accuracy: 0.6319 - val_loss: 0.6407 - val_accuracy: 0.6351\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(train_data, train_labels, epochs=5, batch_size=100, validation_data=[test_data, test_labels])\n",
    "history = model.fit(train_data, train_labels, epochs=5, validation_data=[test_data, test_labels])\n",
    "\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "C5o53b-K7jza",
    "outputId": "5b489948-4745-4201-f66a-86e43099812e"
   },
   "outputs": [],
   "source": [
    "# Visualize the results:\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRY2yKfbkLAn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "FakeNewsClassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs3244",
   "language": "python",
   "name": "cs3244"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
